---
title: AI 编程实践探索
date: 2025-08-25 20:02:55
tags: AI
---

## 一些概念

### Context Length

它限制了模型一次性交互中能够处理的最大token数量。这包括了用户输入的所有内容和模型生成的输出。可以将其类比为资源（如金钱或时间）的总量，你只能在总量内分配这些资源。对于大模型来说，这意味着输入的信息越多，留给输出的空间就越少，反之亦然。

### Context Window

这是模型在生成每个新token时实际参考的前面内容的范围。可以将其类比为在某一特定时间内你能集中注意力的范围，就像你只能专注于手头的有限任务。Context Window决定了在生成过程中，模型可以参考的上下文信息的量。这有助于模型生成连贯且相关的文本，而不会因为参考过多的上下文而导致混乱或不相关的输出。（所以在面对复杂项目时，可以选择具有较长上下文窗口的模型，如claude-4或gpt-4.1等具有128k上下文窗口）

### 128K上下文到底有多大

模型都有一个最佳的处理区间，一般来说，保持在一半以下的上下文使用量是一个比较合适的区间，当超过这个区间后，模型可能会开始遗忘之前的信息或产生一些幻觉

下面是一个参考，128k的上下文到底能干些什么事情

#### 文档处理

- 一篇标准的学术论文通常有5000到10,000个标记。128K的上下文窗口可以处理10到20篇这样的论文内容。
- 一本小说，如《哈利·波特与魔法石》，大约有77,000个标记，128K上下文窗口可以处理接近两本这样的小说内容。

#### 网页内容

- 一个典型的新闻网站主页大约有2000到5000个标记，128K上下文窗口可以处理20到60个这样的主页内容。
- 博客文章通常有1000到3000个标记，128K上下文窗口可以处理40到120篇博客文章内容。

#### 代码

- 复杂的开源项目代码库，像TensorFlow的核心代码库，可能包含数百万行代码。128K上下文窗口可以处理一个中等复杂模块的完整代码，包括注释和文档。

#### 对话

- 在对话场景中，128K标记相当于连续几百个长对话轮次，这对于复杂的客服或技术支持对话非常有用。

## 实践案例

### AI编程目标

与AI进行有目标的对话，然后基于这个目标构建一个Markdown文档，通过Markdown让Agent自动生成代码

### 示例

在上面的交互优化需求中，将hover相机旁的高度显示作为一个最小任务包，让AI实现该部分功能

### 开始对话

新建一个ask对话，告诉AI要解决的问题，以及对这个问题初步的解决方法，然后通过@file和@docs给到Agent必要的上下文（这里可以让Agent快速了解已有项目的框架和背景）

### Tips

- 鼓励让Agent向我提问，比如：完成这个功能我还需要考虑什么？
- 让Agent提出多个不同的方案，然后它进行评估制定完整计划
- 输出对话

### 参考Prompt

整理一下你的代码实施计划，输出一个完成计划（它应包括代码示例、引用相关源文件或相关代码片段），要让一个新来的程序员看懂这个计划，直接就可以写代码，你的计划要以Markdown格式输出

### PS

因为是通过转述给AI生成的代码，这个过程可能会丢失一些信息，比如设计稿中的小点，需求评审过程中讨论的事情，又或是实现过程中与交互/产品讨论的事情

可以在运行后看表现是否和符合预期，可以通过继续对话或自行修改获取希望的效果

## 一些小技巧

### 注意上下文长度

当对话过长或是context过多时（单次tokens过多时），对话的质量就会开始下降，因为Agent会开始遗漏一些细节

将任务分解成更小的块并开始新的会话有助于保持清晰度和专注度

### 明确相关的源代码文件

Agent不会自动查阅所有需要的源码。只要明确引导它读相关库代码，代码质量往往明显提升。比如将项目/二方包接口文件也放入context，会极大提高代码中接口的正确使用。

### 深刻理解需求&丰富知识储备

如果自己都没弄懂某个领域或不清楚具体的需求，Agent很难搭建出完美模块。抽出时间彻底理解需求和相关技术，实际上能大幅提高开发效率。

## 写在最后面

### ✅ 推荐做法

- 任务拆解为最小可执行单元
- 提供精准的上下文信息
- 引导AI进行方案对比和评估
- 输出结构化的实施文档

### ❌ 避免做法

- 一次性塞入过多复杂需求
- 缺少项目背景上下文
- 期望AI理解所有业务细节
- 直接要求完整项目代码

## 参考

- [Building Advanced Software with Cline: A Structured Approach, January 15, 2025](https://cline.bot/blog/building-advanced-software-with-cline-a-structured-approach)
- [大模型｜"Context Length"和"Context Window"不再傻傻分不清楚！智识可乐 20240731](https://www.53ai.com/news/LargeLanguageModel/2024073165281.html)
